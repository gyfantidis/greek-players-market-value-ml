{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 — ML: Predict Market Value\n",
    "**Requires:** Run `01_load_and_filter.ipynb` first.\n",
    "\n",
    "Train and compare regression models to predict the current market value of active Greek players using career stats and player attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "OUTPUTS_PATH = \"../outputs/\"\n",
    "FIGURES_PATH = \"../outputs/figures/\"\n",
    "\n",
    "greek_active      = pd.read_parquet(OUTPUTS_PATH + \"greek_active.parquet\")\n",
    "greek_appearances = pd.read_parquet(OUTPUTS_PATH + \"greek_appearances.parquet\")\n",
    "\n",
    "print(\"greek_active:     \", greek_active.shape)\n",
    "print(\"greek_appearances:\", greek_appearances.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Build Career Stats from Appearances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "career_stats = greek_appearances.groupby(\"player_id\").agg(\n",
    "    total_games   = (\"game_id\",        \"count\"),\n",
    "    total_goals   = (\"goals\",          \"sum\"),\n",
    "    total_assists = (\"assists\",        \"sum\"),\n",
    "    total_yellows = (\"yellow_cards\",   \"sum\"),\n",
    "    total_reds    = (\"red_cards\",      \"sum\"),\n",
    "    total_minutes = (\"minutes_played\", \"sum\"),\n",
    ").reset_index()\n",
    "\n",
    "# Per-90 stats (avoid division by zero)\n",
    "career_stats[\"goals_per_90\"]   = career_stats[\"total_goals\"]   / (career_stats[\"total_minutes\"] / 90).replace(0, np.nan)\n",
    "career_stats[\"assists_per_90\"] = career_stats[\"total_assists\"] / (career_stats[\"total_minutes\"] / 90).replace(0, np.nan)\n",
    "career_stats[\"yellows_per_90\"] = career_stats[\"total_yellows\"] / (career_stats[\"total_minutes\"] / 90).replace(0, np.nan)\n",
    "\n",
    "career_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Join Career Stats with Player Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = greek_active.merge(career_stats, on=\"player_id\", how=\"left\")\n",
    "\n",
    "print(\"Shape after join:\", df.shape)\n",
    "df[[\"name\", \"position\", \"age\", \"market_value_in_eur\",\n",
    "    \"total_games\", \"goals_per_90\", \"assists_per_90\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Prepare Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "le_position = LabelEncoder()\nle_foot     = LabelEncoder()\n\ndf[\"position_enc\"] = le_position.fit_transform(df[\"position\"].fillna(\"Unknown\"))\ndf[\"foot_enc\"]     = le_foot.fit_transform(df[\"foot\"].fillna(\"Unknown\"))\n\n# age² — because age effect on value is non-linear (peak ~22-26, then drops)\ndf[\"age_squared\"] = df[\"age\"] ** 2\n\nFEATURES = [\n    \"age\", \"age_squared\", \"height_in_cm\", \"position_enc\", \"foot_enc\",\n    \"total_games\", \"total_goals\", \"total_assists\",\n    \"total_minutes\", \"total_yellows\", \"total_reds\",\n    \"goals_per_90\", \"assists_per_90\", \"yellows_per_90\",\n]\nTARGET = \"market_value_in_eur\"\n\ndf_ml = df[FEATURES + [TARGET, \"name\"]].dropna(subset=[TARGET])\n\n# Fill remaining NaN in features with median\ndf_ml[FEATURES] = df_ml[FEATURES].fillna(df_ml[FEATURES].median())\n\nprint(f\"Rows for ML: {len(df_ml)}\")\nprint(f\"Missing values: {df_ml[FEATURES].isna().sum().sum()}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "X = df_ml[FEATURES]\n\n# Log transform target — fixes skewed distribution (found in EDA 2.4)\ny_log = np.log1p(df_ml[TARGET])\ny_eur = df_ml[TARGET]  # keep original for final MAE in €\n\nX_train, X_test, y_train, y_test_log = train_test_split(\n    X, y_log, test_size=0.2, random_state=42\n)\n# Keep original € values aligned to test set for evaluation\n_, _, _, y_test_eur = train_test_split(\n    X, y_eur, test_size=0.2, random_state=42\n)\n\nprint(f\"Train: {len(X_train)} | Test: {len(X_test)}\")\nprint(f\"Target (log scale) — mean: {y_train.mean():.2f}, std: {y_train.std():.2f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Train & Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "models = {\n    \"Linear Regression\":  LinearRegression(),\n    \"Random Forest\":      RandomForestRegressor(n_estimators=100, random_state=42),\n    \"Gradient Boosting\":  GradientBoostingRegressor(n_estimators=100, random_state=42),\n}\n\nresults = {}\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n\n    preds_log = model.predict(X_test)\n    preds_eur = np.expm1(preds_log)       # convert back from log to €\n\n    mae = mean_absolute_error(y_test_eur, preds_eur)\n    r2  = r2_score(y_test_log, preds_log) # R² on log scale\n\n    results[name] = {\"MAE (€)\": mae, \"R²\": r2, \"model\": model, \"preds_eur\": preds_eur}\n    print(f\"{name:22s} → MAE: €{mae:>10,.0f}  |  R²: {r2:.3f}\")\n\nbest_name  = max(results, key=lambda k: results[k][\"R²\"])\nbest_model = results[best_name][\"model\"]\nbest_preds = results[best_name][\"preds_eur\"]\nprint(f\"\\nBest model: {best_name}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Predicted vs Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "plt.figure(figsize=(7, 7))\nplt.scatter(y_test_eur / 1e6, best_preds / 1e6, alpha=0.5, color=\"steelblue\")\nmax_val = max(y_test_eur.max(), best_preds.max()) / 1e6\nplt.plot([0, max_val], [0, max_val], \"r--\", label=\"Perfect prediction\")\nplt.xlabel(\"Actual Value (€M)\")\nplt.ylabel(\"Predicted Value (€M)\")\nplt.title(f\"Predicted vs Actual — {best_name}\")\nplt.legend()\nplt.tight_layout()\nplt.savefig(FIGURES_PATH + \"06_predicted_vs_actual.png\", dpi=150)\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(best_model, \"feature_importances_\"):\n",
    "    importances = pd.Series(best_model.feature_importances_, index=FEATURES).sort_values(ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    importances.plot(kind=\"bar\", color=\"steelblue\", edgecolor=\"black\")\n",
    "    plt.title(f\"Feature Importance — {best_name}\")\n",
    "    plt.ylabel(\"Importance\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIGURES_PATH + \"06_feature_importance.png\", dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nTop 5 features:\")\n",
    "    print(importances.head())\n",
    "else:\n",
    "    print(\"Feature importances not available for this model type.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.7 Most Undervalued & Overvalued Players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Predict on full dataset and convert back to €\ndf_ml[\"predicted_value\"] = np.expm1(best_model.predict(df_ml[FEATURES]))\ndf_ml[\"residual\"]        = df_ml[\"predicted_value\"] - df_ml[TARGET]\ndf_ml[\"residual_M\"]      = df_ml[\"residual\"] / 1e6\n\nprint(\"=== Most Undervalued (model thinks they're worth more) ===\")\nprint(df_ml.nsmallest(5, \"residual\")[[\"name\", TARGET, \"predicted_value\", \"residual_M\"]]\n      .rename(columns={TARGET: \"actual_eur\", \"predicted_value\": \"predicted_eur\"})\n      .to_string(index=False))\n\nprint(\"\\n=== Most Overvalued (model thinks they're worth less) ===\")\nprint(df_ml.nlargest(5, \"residual\")[[\"name\", TARGET, \"predicted_value\", \"residual_M\"]]\n      .rename(columns={TARGET: \"actual_eur\", \"predicted_value\": \"predicted_eur\"})\n      .to_string(index=False))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.8 Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(OUTPUTS_PATH + \"models/best_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "print(f\"Saved {best_name} to outputs/models/best_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}